# Classificação de Vinhos - KNN com K-Fold Cross-Validation

# Importação das bibliotecas necessárias
import pandas as pd
import numpy as np
from sklearn.model_selection import KFold
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score

# 1. Leitura dos Dados
# URL do dataset Wine
url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data'

# Nome das colunas em português BR
column_names_pt_br = [
    'classe',
    'alcool',
    'acido_malico',
    'cinzas',
    'alcalinidade_de_cinzas',
    'magnesio',
    'fenois_totais',
    'flavanoides',
    'fenois_nao_flavanoides',
    'proantocianinas',
    'intensidade_de_cor',
    'matiz',
    'od280_od315_de_vinhos_diluidos',
    'prolina'
]

# Ler o arquivo CSV com as colunas especificadas
vinhos = pd.read_csv(url, names=column_names_pt_br, dtype={'classe': object})

# Visualizar as primeiras linhas
vinhos.head()
2. Pré-processamento dos Dados
python

# Separar as variáveis
X = vinhos.drop(columns=['classe'])
y = vinhos['classe']
3. Estrutura do Experimento com KFold
python

# Função para realizar K-Fold Cross-Validation
def kfold_experimento(X, y, k_values, random_state):
    resultados = {}
    
    # Configuração do KFold
    kf = KFold(n_splits=10, shuffle=True, random_state=random_state)
    
    for k in k_values:
        acuracias = []
        
        for train_index, test_index in kf.split(X):
            # Divisão de treino e teste
            X_train, X_test = X.iloc[train_index], X.iloc[test_index]
            y_train, y_test = y.iloc[train_index], y.iloc[test_index]
            
            # Treinamento do modelo KNN
            knn = KNeighborsClassifier(n_neighbors=k)
            knn.fit(X_train, y_train)
            
            # Previsões e cálculo da acurácia
            y_pred = knn.predict(X_test)
            acuracias.append(accuracy_score(y_test, y_pred))
        
        # Armazenar a média e o desvio padrão das acurácias
        resultados[k] = {
            'mean_accuracy': np.mean(acuracias),
            'std_accuracy': np.std(acuracias)
        }
    
    return resultados

# Valores de k e random_state
k_values = [3, 5]
random_states = [42, 17, 24]

# Dicionário para armazenar os resultados de cada random_state
todos_resultados = {}

# Executando os experimentos
for random_state in random_states:
    print(f"\nExperimento com random_state={random_state}")
    resultados = kfold_experimento(X, y, k_values, random_state)
    todos_resultados[random_state] = resultados
    
    # Exibir os resultados
    for k, metricas in resultados.items():
        print(f"k={k}: Acurácia Média={metricas['mean_accuracy']:.4f}, Desvio Padrão={metricas['std_accuracy']:.4f}")
4. Análise Final
python

# Comparação final
print("\nComparação Final dos Resultados:")
for random_state, resultados in todos_resultados.items():
    print(f"\nRandom State: {random_state}")
    for k, metricas in resultados.items():
        print(f"k={k}: Acurácia Média={metricas['mean_accuracy']:.4f}, Desvio Padrão={metricas['std_accuracy']:.4f}")

# Identificar o melhor modelo
melhores_modelos = {}
for random_state, resultados in todos_resultados.items():
    melhor_k = max(resultados, key=lambda k: resultados[k]['mean_accuracy'])
    melhores_modelos[random_state] = melhor_k

print("\nMelhores Modelos por Random State:")
for random_state, melhor_k in melhores_modelos.items():
    print(f"Random State {random_state}: Melhor k={melhor_k}")
